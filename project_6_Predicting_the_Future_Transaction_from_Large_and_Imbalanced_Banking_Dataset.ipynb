{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "179cA4X-JBJOmJnJvm8L3dKwQw2b0q8zR",
      "authorship_tag": "ABX9TyMX8f5O0h1OxJ+PAdUWolNZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Boudia27/Projects/blob/main/project_6_Predicting_the_Future_Transaction_from_Large_and_Imbalanced_Banking_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols"
      ],
      "metadata": {
        "id": "X2hZCSBdV2Ln"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEZy4U_iU873",
        "outputId": "1d22c0ff-60e6-4fb0-83e4-c5e14c874517"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ID_code  target\n",
            "0  test_0       0\n",
            "1  test_1       0\n",
            "2  test_2       0\n",
            "3  test_3       0\n",
            "4  test_4       0\n",
            "  ID_code    var_0    var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
            "0  test_0  11.0656   7.7798  12.9536  9.4292  11.4327 -2.3805  5.8493   \n",
            "1  test_1   8.5304   1.2543  11.3047  5.1858   9.1974 -4.0117  6.0196   \n",
            "2  test_2   5.4827 -10.3581  10.1407  7.0479  10.2628  9.8052  4.8950   \n",
            "3  test_3   8.5374  -1.3222  12.0220  6.5749   8.8458  3.1744  4.9397   \n",
            "4  test_4  11.7058  -0.1327  14.1295  7.7506   9.1035 -8.5848  6.8595   \n",
            "\n",
            "     var_7   var_8  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
            "0  18.2675  2.1337  ...  -2.1556  11.8495  -1.4300   2.4508  13.7112   2.4669   \n",
            "1  18.6316 -4.4131  ...  10.6165   8.8349   0.9403  10.1282  15.5765   0.4773   \n",
            "2  20.2537  1.5233  ...  -0.7484  10.9935   1.9803   2.1800  12.9813   2.1281   \n",
            "3  20.5660  3.3755  ...   9.5702   9.0766   1.6580   3.5813  15.1874   3.1656   \n",
            "4  10.6048  2.9890  ...   4.2259   9.1723   1.2835   3.3778  19.5542  -0.2860   \n",
            "\n",
            "   var_196  var_197  var_198  var_199  \n",
            "0   4.3654  10.7200  15.4722  -8.7197  \n",
            "1  -1.4852   9.8714  19.1293 -20.9760  \n",
            "2  -7.1086   7.0618  19.8956 -23.1794  \n",
            "3   3.9567   9.2295  13.0168  -4.2108  \n",
            "4  -5.1612   7.2882  13.9260  -9.1846  \n",
            "\n",
            "[5 rows x 201 columns]\n",
            "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
            "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
            "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
            "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
            "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
            "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
            "\n",
            "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
            "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
            "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
            "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
            "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
            "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
            "\n",
            "   var_196  var_197  var_198  var_199  \n",
            "0   7.8784   8.5635  12.7803  -1.0914  \n",
            "1   8.1267   8.7889  18.3560   1.9518  \n",
            "2  -6.5213   8.2675  14.7222   0.3965  \n",
            "3  -2.9275  10.2922  17.9697  -8.9996  \n",
            "4   3.9267   9.5031  17.9974  -8.8104  \n",
            "\n",
            "[5 rows x 202 columns]\n"
          ]
        }
      ],
      "source": [
        "df1 = pd.read_csv('/content/drive/MyDrive/Projects/project_6_Predicting_the_Future_Transaction_from_Large_and_Imbalanced_Banking_Dataset/sample_submission.csv')\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/Projects/project_6_Predicting_the_Future_Transaction_from_Large_and_Imbalanced_Banking_Dataset/test.csv')\n",
        "df3 = pd.read_csv('/content/drive/MyDrive/Projects/project_6_Predicting_the_Future_Transaction_from_Large_and_Imbalanced_Banking_Dataset/train.csv')\n",
        "\n",
        "print(df1.head())\n",
        "print(df2.head())\n",
        "print(df3.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df1.columns)\n",
        "print(df2.columns)\n",
        "print(df3.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsloMu9vWAi9",
        "outputId": "f251ec2b-f007-4db0-a25c-9b484eb89596"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['ID_code', 'target'], dtype='object')\n",
            "Index(['ID_code', 'var_0', 'var_1', 'var_2', 'var_3', 'var_4', 'var_5',\n",
            "       'var_6', 'var_7', 'var_8',\n",
            "       ...\n",
            "       'var_190', 'var_191', 'var_192', 'var_193', 'var_194', 'var_195',\n",
            "       'var_196', 'var_197', 'var_198', 'var_199'],\n",
            "      dtype='object', length=201)\n",
            "Index(['ID_code', 'target', 'var_0', 'var_1', 'var_2', 'var_3', 'var_4',\n",
            "       'var_5', 'var_6', 'var_7',\n",
            "       ...\n",
            "       'var_190', 'var_191', 'var_192', 'var_193', 'var_194', 'var_195',\n",
            "       'var_196', 'var_197', 'var_198', 'var_199'],\n",
            "      dtype='object', length=202)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df1.describe())\n",
        "print(df2.describe())\n",
        "print(df3.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rFjYH8rWF72",
        "outputId": "ddd7341b-9e41-44b2-b249-da4afcee3fa3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         target\n",
            "count  200000.0\n",
            "mean        0.0\n",
            "std         0.0\n",
            "min         0.0\n",
            "25%         0.0\n",
            "50%         0.0\n",
            "75%         0.0\n",
            "max         0.0\n",
            "               var_0          var_1          var_2          var_3  \\\n",
            "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
            "mean       10.658737      -1.624244      10.707452       6.788214   \n",
            "std         3.036716       4.040509       2.633888       2.052724   \n",
            "min         0.188700     -15.043400       2.355200      -0.022400   \n",
            "25%         8.442975      -4.700125       8.735600       5.230500   \n",
            "50%        10.513800      -1.590500      10.560700       6.822350   \n",
            "75%        12.739600       1.343400      12.495025       8.327600   \n",
            "max        22.323400       9.385100      18.714100      13.142000   \n",
            "\n",
            "               var_4          var_5          var_6          var_7  \\\n",
            "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
            "mean       11.076399      -5.050558       5.415164      16.529143   \n",
            "std         1.616456       7.869293       0.864686       3.424482   \n",
            "min         5.484400     -27.767000       2.216400       5.713700   \n",
            "25%         9.891075     -11.201400       4.772600      13.933900   \n",
            "50%        11.099750      -4.834100       5.391600      16.422700   \n",
            "75%        12.253400       0.942575       6.005800      19.094550   \n",
            "max        16.037100      17.253700       8.302500      28.292800   \n",
            "\n",
            "               var_8          var_9  ...        var_190        var_191  \\\n",
            "count  200000.000000  200000.000000  ...  200000.000000  200000.000000   \n",
            "mean        0.277135       7.569407  ...       3.189766       7.458269   \n",
            "std         3.333375       1.231865  ...       4.551239       3.025189   \n",
            "min        -9.956000       4.243300  ...     -14.093300      -2.407000   \n",
            "25%        -2.303900       6.623800  ...      -0.095000       5.166500   \n",
            "50%         0.372000       7.632000  ...       3.162400       7.379000   \n",
            "75%         2.930025       8.584825  ...       6.336475       9.531100   \n",
            "max         9.665500      11.003600  ...      20.359000      16.716500   \n",
            "\n",
            "             var_192        var_193        var_194        var_195  \\\n",
            "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
            "mean        1.925944       3.322016      17.996967      -0.133657   \n",
            "std         1.479966       3.995599       3.140652       1.429678   \n",
            "min        -3.340900     -11.413100       9.382800      -4.911900   \n",
            "25%         0.882975       0.587600      15.634775      -1.160700   \n",
            "50%         1.892600       3.428500      17.977600      -0.162000   \n",
            "75%         2.956000       6.174200      20.391725       0.837900   \n",
            "max         8.005000      17.632600      27.947800       4.545400   \n",
            "\n",
            "             var_196        var_197        var_198        var_199  \n",
            "count  200000.000000  200000.000000  200000.000000  200000.000000  \n",
            "mean        2.290899       8.912428      15.869184      -3.246342  \n",
            "std         5.446346       0.920904       3.008717      10.398589  \n",
            "min       -13.944200       6.169600       6.584000     -39.457800  \n",
            "25%        -1.948600       8.260075      13.847275     -11.124000  \n",
            "50%         2.403600       8.892800      15.943400      -2.725950  \n",
            "75%         6.519800       9.595900      18.045200       4.935400  \n",
            "max        15.920700      12.275800      26.538400      27.907400  \n",
            "\n",
            "[8 rows x 200 columns]\n",
            "              target          var_0          var_1          var_2  \\\n",
            "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
            "mean        0.100490      10.679914      -1.627622      10.715192   \n",
            "std         0.300653       3.040051       4.050044       2.640894   \n",
            "min         0.000000       0.408400     -15.043400       2.117100   \n",
            "25%         0.000000       8.453850      -4.740025       8.722475   \n",
            "50%         0.000000      10.524750      -1.608050      10.580000   \n",
            "75%         0.000000      12.758200       1.358625      12.516700   \n",
            "max         1.000000      20.315000      10.376800      19.353000   \n",
            "\n",
            "               var_3          var_4          var_5          var_6  \\\n",
            "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
            "mean        6.796529      11.078333      -5.065317       5.408949   \n",
            "std         2.043319       1.623150       7.863267       0.866607   \n",
            "min        -0.040200       5.074800     -32.562600       2.347300   \n",
            "25%         5.254075       9.883175     -11.200350       4.767700   \n",
            "50%         6.825000      11.108250      -4.833150       5.385100   \n",
            "75%         8.324100      12.261125       0.924800       6.003000   \n",
            "max        13.188300      16.671400      17.251600       8.447700   \n",
            "\n",
            "               var_7          var_8  ...        var_190        var_191  \\\n",
            "count  200000.000000  200000.000000  ...  200000.000000  200000.000000   \n",
            "mean       16.545850       0.284162  ...       3.234440       7.438408   \n",
            "std         3.418076       3.332634  ...       4.559922       3.023272   \n",
            "min         5.349700     -10.505500  ...     -14.093300      -2.691700   \n",
            "25%        13.943800      -2.317800  ...      -0.058825       5.157400   \n",
            "50%        16.456800       0.393700  ...       3.203600       7.347750   \n",
            "75%        19.102900       2.937900  ...       6.406200       9.512525   \n",
            "max        27.691800      10.151300  ...      18.440900      16.716500   \n",
            "\n",
            "             var_192        var_193        var_194        var_195  \\\n",
            "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
            "mean        1.927839       3.331774      17.993784      -0.142088   \n",
            "std         1.478423       3.992030       3.135162       1.429372   \n",
            "min        -3.814500     -11.783400       8.694400      -5.261000   \n",
            "25%         0.889775       0.584600      15.629800      -1.170700   \n",
            "50%         1.901300       3.396350      17.957950      -0.172700   \n",
            "75%         2.949500       6.205800      20.396525       0.829600   \n",
            "max         8.402400      18.281800      27.928800       4.272900   \n",
            "\n",
            "             var_196        var_197        var_198        var_199  \n",
            "count  200000.000000  200000.000000  200000.000000  200000.000000  \n",
            "mean        2.303335       8.908158      15.870720      -3.326537  \n",
            "std         5.454369       0.921625       3.010945      10.438015  \n",
            "min       -14.209600       5.960600       6.299300     -38.852800  \n",
            "25%        -1.946925       8.252800      13.829700     -11.208475  \n",
            "50%         2.408900       8.888200      15.934050      -2.819550  \n",
            "75%         6.556725       9.593300      18.064725       4.836800  \n",
            "max        18.321500      12.000400      26.079100      28.500700  \n",
            "\n",
            "[8 rows x 201 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean DATA"
      ],
      "metadata": {
        "id": "hFja1vY9WSNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Remove duplicates\n",
        "df1 = df1.drop_duplicates()\n",
        "df2 = df2.drop_duplicates()\n",
        "df3 = df3.drop_duplicates()\n",
        "\n",
        "# 2. Handle missing values\n",
        "df1 = df1.dropna()\n",
        "df2 = df2.dropna()\n",
        "df3 = df3.dropna()\n",
        "\n",
        "\n",
        "# Print the cleaned dataframes\n",
        "print(df1.head())\n",
        "print(df2.head())\n",
        "print(df3.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZRxGVxWWKSV",
        "outputId": "cf521428-2ee7-4892-ccfa-4c9ee9ff4d8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ID_code  target\n",
            "0  test_0       0\n",
            "1  test_1       0\n",
            "2  test_2       0\n",
            "3  test_3       0\n",
            "4  test_4       0\n",
            "  ID_code    var_0    var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
            "0  test_0  11.0656   7.7798  12.9536  9.4292  11.4327 -2.3805  5.8493   \n",
            "1  test_1   8.5304   1.2543  11.3047  5.1858   9.1974 -4.0117  6.0196   \n",
            "2  test_2   5.4827 -10.3581  10.1407  7.0479  10.2628  9.8052  4.8950   \n",
            "3  test_3   8.5374  -1.3222  12.0220  6.5749   8.8458  3.1744  4.9397   \n",
            "4  test_4  11.7058  -0.1327  14.1295  7.7506   9.1035 -8.5848  6.8595   \n",
            "\n",
            "     var_7   var_8  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
            "0  18.2675  2.1337  ...  -2.1556  11.8495  -1.4300   2.4508  13.7112   2.4669   \n",
            "1  18.6316 -4.4131  ...  10.6165   8.8349   0.9403  10.1282  15.5765   0.4773   \n",
            "2  20.2537  1.5233  ...  -0.7484  10.9935   1.9803   2.1800  12.9813   2.1281   \n",
            "3  20.5660  3.3755  ...   9.5702   9.0766   1.6580   3.5813  15.1874   3.1656   \n",
            "4  10.6048  2.9890  ...   4.2259   9.1723   1.2835   3.3778  19.5542  -0.2860   \n",
            "\n",
            "   var_196  var_197  var_198  var_199  \n",
            "0   4.3654  10.7200  15.4722  -8.7197  \n",
            "1  -1.4852   9.8714  19.1293 -20.9760  \n",
            "2  -7.1086   7.0618  19.8956 -23.1794  \n",
            "3   3.9567   9.2295  13.0168  -4.2108  \n",
            "4  -5.1612   7.2882  13.9260  -9.1846  \n",
            "\n",
            "[5 rows x 201 columns]\n",
            "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
            "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
            "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
            "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
            "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
            "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
            "\n",
            "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
            "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
            "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
            "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
            "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
            "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
            "\n",
            "   var_196  var_197  var_198  var_199  \n",
            "0   7.8784   8.5635  12.7803  -1.0914  \n",
            "1   8.1267   8.7889  18.3560   1.9518  \n",
            "2  -6.5213   8.2675  14.7222   0.3965  \n",
            "3  -2.9275  10.2922  17.9697  -8.9996  \n",
            "4   3.9267   9.5031  17.9974  -8.8104  \n",
            "\n",
            "[5 rows x 202 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformation: Standardization"
      ],
      "metadata": {
        "id": "_DBypS-AZ4Uf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply standardization to numeric variables\n",
        "numeric_columns = df2.columns[1:]  # Assuming the numeric columns start from index 1\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df2[numeric_columns] = scaler.fit_transform(df2[numeric_columns])\n",
        "df3[numeric_columns] = scaler.transform(df3[numeric_columns])\n",
        "\n",
        "# Print the transformed dataframes\n",
        "print(df1.head())\n",
        "print(df2.head())\n",
        "print(df3.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwwzbklmZvOv",
        "outputId": "34f43080-6f11-4a5c-eab4-c70992482ea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ID_code  target\n",
            "0  test_0     0.0\n",
            "1  test_1     0.0\n",
            "2  test_2     0.0\n",
            "3  test_3     0.0\n",
            "4  test_4     0.0\n",
            "  ID_code     var_0     var_1     var_2     var_3     var_4     var_5  \\\n",
            "0  test_0  0.133982  2.327446  0.852790  1.286580  0.220422  0.339302   \n",
            "1  test_1 -0.700870  0.712423  0.226756 -0.780630 -1.162422  0.132014   \n",
            "2  test_2 -1.704490 -2.161579 -0.215177  0.126508 -0.503324  1.887818   \n",
            "3  test_3 -0.698565  0.074754  0.499091 -0.103918 -1.379935  1.045199   \n",
            "4  test_4  0.344802  0.369148  1.299241  0.468835 -1.220512 -0.449119   \n",
            "\n",
            "      var_6     var_7     var_8  ...   var_190   var_191   var_192   var_193  \\\n",
            "0  0.502075  0.507628  0.556964  ... -1.174489  1.451559 -2.267588 -0.218044   \n",
            "1  0.699025  0.613951 -1.407056  ...  1.631809  0.455057 -0.665993  1.703425   \n",
            "2 -0.601566  1.087629  0.373846  ... -0.865298  1.168601  0.036728 -0.285819   \n",
            "3 -0.549870  1.178826  0.929500  ...  1.401915  0.534953 -0.181048  0.064893   \n",
            "4  1.670363 -1.730001  0.813551  ...  0.227660  0.566588 -0.434095  0.013961   \n",
            "\n",
            "    var_194   var_195   var_196   var_197   var_198   var_199  \n",
            "0 -1.364614  1.818985  0.380899  1.962828 -0.131945 -0.526357  \n",
            "1 -0.770691  0.427340 -0.693329  1.041340  1.083560 -1.705010  \n",
            "2 -1.597018  1.582008 -1.725840 -2.009582  1.338254 -1.916905  \n",
            "3 -0.894583  2.307698  0.305857  0.344306 -0.948042 -0.092749  \n",
            "4  0.495832 -0.106558 -1.368278 -1.763736 -0.645853 -0.571065  \n",
            "\n",
            "[5 rows x 201 columns]\n",
            "   ID_code  target     var_0     var_1     var_2     var_3     var_4  \\\n",
            "0  train_0       0 -0.570762 -1.277579  0.455847 -0.825838  0.237743   \n",
            "1  train_1       0  0.277229 -0.624442  1.196465 -0.681639  0.795446   \n",
            "2  train_2       0 -0.674888 -0.277554  0.521302  0.538109 -0.305545   \n",
            "3  train_3       0  0.132269 -0.130567 -0.666413  0.198510  0.933032   \n",
            "4  train_4       0 -0.270634  0.034858  0.822796 -0.073422  0.742862   \n",
            "\n",
            "      var_5     var_6     var_7  ...   var_190   var_191   var_192   var_193  \\\n",
            "0 -0.537895 -0.342858  0.612490  ...  0.273692 -1.154995  0.817896 -0.408204   \n",
            "1  1.536846  0.237816  0.001360  ...  0.978271  0.086980  0.444441  1.909502   \n",
            "2 -0.512518  1.766583 -0.558814  ... -0.062415  0.770939 -0.172669 -0.409506   \n",
            "3  0.408482  0.494557 -0.468435  ...  0.280547 -0.897457 -0.816334 -0.475679   \n",
            "4  0.952967  0.607547  0.794942  ... -1.028352  0.681986 -1.403241  1.469667   \n",
            "\n",
            "    var_194   var_195   var_196   var_197   var_198   var_199  \n",
            "0  0.167397 -1.583677  1.025920 -0.378898 -1.026647  0.207235  \n",
            "1 -0.817178  1.516119  1.071510 -0.134138  0.826539  0.499890  \n",
            "2  1.148565  2.290981 -1.618006 -0.700322 -0.381221  0.350322  \n",
            "3  1.604044 -0.795246 -0.958149  1.498283  0.698145 -0.553274  \n",
            "4 -1.499491 -0.964166  0.300349  0.641406  0.707352 -0.535080  \n",
            "\n",
            "[5 rows x 202 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate central measures"
      ],
      "metadata": {
        "id": "70hJjm23aLk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming numeric columns start from index 1\n",
        "numeric_columns = df2.columns[1:]\n",
        "\n",
        "# Calculate mean\n",
        "mean_df2 = df2[numeric_columns].mean()\n",
        "mean_df3 = df3[numeric_columns].mean()\n",
        "\n",
        "# Calculate median\n",
        "median_df2 = df2[numeric_columns].median()\n",
        "median_df3 = df3[numeric_columns].median()\n",
        "\n",
        "# Calculate mode\n",
        "mode_df2 = df2[numeric_columns].mode().iloc[0]  # Assuming there is a unique mode\n",
        "mode_df3 = df3[numeric_columns].mode().iloc[0]  # Assuming there is a unique mode\n",
        "\n",
        "# Print the central measures\n",
        "print(\"Mean (df2):\\n\", mean_df2)\n",
        "print(\"Mean (df3):\\n\", mean_df3)\n",
        "\n",
        "print(\"Median (df2):\\n\", median_df2)\n",
        "print(\"Median (df3):\\n\", median_df3)\n",
        "\n",
        "print(\"Mode (df2):\\n\", mode_df2)\n",
        "print(\"Mode (df3):\\n\", mode_df3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyLdctvZaL2n",
        "outputId": "09b9c63d-ed9c-4f65-9b4c-b798fa6ab3ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean (df2):\n",
            " var_0      4.919620e-16\n",
            "var_1      1.236344e-17\n",
            "var_2     -6.937739e-16\n",
            "var_3     -1.919176e-16\n",
            "var_4     -4.163425e-16\n",
            "               ...     \n",
            "var_195    3.339551e-18\n",
            "var_196    6.313172e-17\n",
            "var_197    1.917151e-15\n",
            "var_198   -1.335820e-17\n",
            "var_199   -1.634248e-17\n",
            "Length: 200, dtype: float64\n",
            "Mean (df3):\n",
            " var_0      0.006974\n",
            "var_1     -0.000836\n",
            "var_2      0.002939\n",
            "var_3      0.004051\n",
            "var_4      0.001197\n",
            "             ...   \n",
            "var_195   -0.005897\n",
            "var_196    0.002283\n",
            "var_197   -0.004637\n",
            "var_198    0.000511\n",
            "var_199   -0.007712\n",
            "Length: 200, dtype: float64\n",
            "Median (df2):\n",
            " var_0     -0.047728\n",
            "var_1      0.008351\n",
            "var_2     -0.055717\n",
            "var_3      0.016630\n",
            "var_4      0.014446\n",
            "             ...   \n",
            "var_195   -0.019825\n",
            "var_196    0.020693\n",
            "var_197   -0.021314\n",
            "var_198    0.024667\n",
            "var_199    0.050045\n",
            "Length: 200, dtype: float64\n",
            "Median (df3):\n",
            " var_0     -0.044122\n",
            "var_1      0.004008\n",
            "var_2     -0.048389\n",
            "var_3      0.017921\n",
            "var_4      0.019704\n",
            "             ...   \n",
            "var_195   -0.027309\n",
            "var_196    0.021666\n",
            "var_197   -0.026309\n",
            "var_198    0.021560\n",
            "var_199    0.041043\n",
            "Length: 200, dtype: float64\n",
            "Mode (df2):\n",
            " var_0     -0.369458\n",
            "var_1     -0.503838\n",
            "var_2     -0.134042\n",
            "var_3      0.862849\n",
            "var_4     -0.362522\n",
            "             ...   \n",
            "var_195   -0.055987\n",
            "var_196    0.697718\n",
            "var_197    0.639777\n",
            "var_198   -0.006476\n",
            "var_199   -0.698333\n",
            "Name: 0, Length: 200, dtype: float64\n",
            "Mode (df3):\n",
            " var_0     -0.656578\n",
            "var_1     -0.235381\n",
            "var_2     -0.591428\n",
            "var_3      0.007154\n",
            "var_4     -0.114633\n",
            "             ...   \n",
            "var_195   -0.560507\n",
            "var_196   -0.790715\n",
            "var_197   -0.939001\n",
            "var_198    0.334634\n",
            "var_199   -0.707238\n",
            "Name: 0, Length: 200, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dispersion measures"
      ],
      "metadata": {
        "id": "PWVJoz2iajGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming numeric columns start from index 1\n",
        "numeric_columns = df2.columns[1:]\n",
        "\n",
        "# Calculate range\n",
        "range_df2 = df2[numeric_columns].max() - df2[numeric_columns].min()\n",
        "range_df3 = df3[numeric_columns].max() - df3[numeric_columns].min()\n",
        "\n",
        "# Calculate variance\n",
        "variance_df2 = df2[numeric_columns].var()\n",
        "variance_df3 = df3[numeric_columns].var()\n",
        "\n",
        "# Calculate standard deviation\n",
        "std_deviation_df2 = df2[numeric_columns].std()\n",
        "std_deviation_df3 = df3[numeric_columns].std()\n",
        "\n",
        "# Print the dispersion measures\n",
        "print(\"Range (df2):\\n\", range_df2)\n",
        "print(\"Range (df3):\\n\", range_df3)\n",
        "\n",
        "print(\"Variance (df2):\\n\", variance_df2)\n",
        "print(\"Variance (df3):\\n\", variance_df3)\n",
        "\n",
        "print(\"Standard Deviation (df2):\\n\", std_deviation_df2)\n",
        "print(\"Standard Deviation (df3):\\n\", std_deviation_df3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntflobugakA4",
        "outputId": "4699428e-642a-4f5b-e8a8-f99a0c1aabf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Range (df2):\n",
            " var_0      7.289045\n",
            "var_1      6.045912\n",
            "var_2      6.210947\n",
            "var_3      6.413154\n",
            "var_4      6.528310\n",
            "             ...   \n",
            "var_195    6.615002\n",
            "var_196    5.483489\n",
            "var_197    6.630673\n",
            "var_198    6.632212\n",
            "var_199    6.478318\n",
            "Length: 200, dtype: float64\n",
            "Range (df3):\n",
            " var_0      6.555322\n",
            "var_1      6.291352\n",
            "var_2      6.543915\n",
            "var_3      6.444381\n",
            "var_4      7.174107\n",
            "             ...   \n",
            "var_195    6.668580\n",
            "var_196    5.973029\n",
            "var_197    6.558570\n",
            "var_198    6.574181\n",
            "var_199    6.477193\n",
            "Length: 200, dtype: float64\n",
            "Variance (df2):\n",
            " var_0      1.000005\n",
            "var_1      1.000005\n",
            "var_2      1.000005\n",
            "var_3      1.000005\n",
            "var_4      1.000005\n",
            "             ...   \n",
            "var_195    1.000005\n",
            "var_196    1.000005\n",
            "var_197    1.000005\n",
            "var_198    1.000005\n",
            "var_199    1.000005\n",
            "Length: 200, dtype: float64\n",
            "Variance (df3):\n",
            " var_0      1.002203\n",
            "var_1      1.004730\n",
            "var_2      1.005332\n",
            "var_3      0.990863\n",
            "var_4      1.008304\n",
            "             ...   \n",
            "var_195    0.999577\n",
            "var_196    1.002954\n",
            "var_197    1.001572\n",
            "var_198    1.001487\n",
            "var_199    1.007602\n",
            "Length: 200, dtype: float64\n",
            "Standard Deviation (df2):\n",
            " var_0      1.000003\n",
            "var_1      1.000003\n",
            "var_2      1.000003\n",
            "var_3      1.000003\n",
            "var_4      1.000003\n",
            "             ...   \n",
            "var_195    1.000003\n",
            "var_196    1.000003\n",
            "var_197    1.000003\n",
            "var_198    1.000003\n",
            "var_199    1.000003\n",
            "Length: 200, dtype: float64\n",
            "Standard Deviation (df3):\n",
            " var_0      1.001101\n",
            "var_1      1.002362\n",
            "var_2      1.002662\n",
            "var_3      0.995421\n",
            "var_4      1.004143\n",
            "             ...   \n",
            "var_195    0.999789\n",
            "var_196    1.001476\n",
            "var_197    1.000786\n",
            "var_198    1.000743\n",
            "var_199    1.003794\n",
            "Length: 200, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate mean, standard deviation, and median for numerical variables"
      ],
      "metadata": {
        "id": "6R-FeZ00aoDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming numerical columns start from index 1\n",
        "numeric_columns = df2.columns[1:]\n",
        "\n",
        "# Calculate mean\n",
        "mean_df2 = df2[numeric_columns].mean()\n",
        "mean_df3 = df3[numeric_columns].mean()\n",
        "\n",
        "# Calculate standard deviation\n",
        "std_dev_df2 = df2[numeric_columns].std()\n",
        "std_dev_df3 = df3[numeric_columns].std()\n",
        "\n",
        "# Calculate median\n",
        "median_df2 = df2[numeric_columns].median()\n",
        "median_df3 = df3[numeric_columns].median()\n",
        "\n",
        "# Print the calculated measures\n",
        "print(\"Mean (df2):\\n\", mean_df2)\n",
        "print(\"Mean (df3):\\n\", mean_df3)\n",
        "\n",
        "print(\"Standard Deviation (df2):\\n\", std_dev_df2)\n",
        "print(\"Standard Deviation (df3):\\n\", std_dev_df3)\n",
        "\n",
        "print(\"Median (df2):\\n\", median_df2)\n",
        "print(\"Median (df3):\\n\", median_df3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPkoQ1DDarr-",
        "outputId": "54f4cb52-f6ce-4468-a0e4-cb7c2b0b2219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean (df2):\n",
            " var_0      4.919620e-16\n",
            "var_1      1.236344e-17\n",
            "var_2     -6.937739e-16\n",
            "var_3     -1.919176e-16\n",
            "var_4     -4.163425e-16\n",
            "               ...     \n",
            "var_195    3.339551e-18\n",
            "var_196    6.313172e-17\n",
            "var_197    1.917151e-15\n",
            "var_198   -1.335820e-17\n",
            "var_199   -1.634248e-17\n",
            "Length: 200, dtype: float64\n",
            "Mean (df3):\n",
            " var_0      0.006974\n",
            "var_1     -0.000836\n",
            "var_2      0.002939\n",
            "var_3      0.004051\n",
            "var_4      0.001197\n",
            "             ...   \n",
            "var_195   -0.005897\n",
            "var_196    0.002283\n",
            "var_197   -0.004637\n",
            "var_198    0.000511\n",
            "var_199   -0.007712\n",
            "Length: 200, dtype: float64\n",
            "Standard Deviation (df2):\n",
            " var_0      1.000003\n",
            "var_1      1.000003\n",
            "var_2      1.000003\n",
            "var_3      1.000003\n",
            "var_4      1.000003\n",
            "             ...   \n",
            "var_195    1.000003\n",
            "var_196    1.000003\n",
            "var_197    1.000003\n",
            "var_198    1.000003\n",
            "var_199    1.000003\n",
            "Length: 200, dtype: float64\n",
            "Standard Deviation (df3):\n",
            " var_0      1.001101\n",
            "var_1      1.002362\n",
            "var_2      1.002662\n",
            "var_3      0.995421\n",
            "var_4      1.004143\n",
            "             ...   \n",
            "var_195    0.999789\n",
            "var_196    1.001476\n",
            "var_197    1.000786\n",
            "var_198    1.000743\n",
            "var_199    1.003794\n",
            "Length: 200, dtype: float64\n",
            "Median (df2):\n",
            " var_0     -0.047728\n",
            "var_1      0.008351\n",
            "var_2     -0.055717\n",
            "var_3      0.016630\n",
            "var_4      0.014446\n",
            "             ...   \n",
            "var_195   -0.019825\n",
            "var_196    0.020693\n",
            "var_197   -0.021314\n",
            "var_198    0.024667\n",
            "var_199    0.050045\n",
            "Length: 200, dtype: float64\n",
            "Median (df3):\n",
            " var_0     -0.044122\n",
            "var_1      0.004008\n",
            "var_2     -0.048389\n",
            "var_3      0.017921\n",
            "var_4      0.019704\n",
            "             ...   \n",
            "var_195   -0.027309\n",
            "var_196    0.021666\n",
            "var_197   -0.026309\n",
            "var_198    0.021560\n",
            "var_199    0.041043\n",
            "Length: 200, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hypothesis\n",
        "#### H0 (Null Hypothesis): This hypothesis assumes that there is no significant relationship or difference between id and var.\n",
        "\n",
        "#### H1 (Alternative Hypothesis): This hypothesis assumes that there is a significant relationship or difference between id and var."
      ],
      "metadata": {
        "id": "YNlDQLktcwKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "# Read the data from the CSV files\n",
        "df1 = pd.read_csv('/content/drive/MyDrive/Projects/project_6_Predicting_the_Future_Transaction_from_Large_and_Imbalanced_Banking_Dataset/sample_submission.csv')\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/Projects/project_6_Predicting_the_Future_Transaction_from_Large_and_Imbalanced_Banking_Dataset/test.csv')\n",
        "df3 = pd.read_csv('/content/drive/MyDrive/Projects/project_6_Predicting_the_Future_Transaction_from_Large_and_Imbalanced_Banking_Dataset/train.csv')\n",
        "\n",
        "# Assuming 'target', 'ID_code', and variables starting from 'var_0' are columns in the dataframes\n",
        "\n",
        "# Merge the dataframes\n",
        "merged_df = pd.concat([df1, df2, df3], axis=0)\n",
        "\n",
        "# Perform two-way ANOVA\n",
        "model = ols('target ~ ID_code + var_0 + var_1 + var_2 + var_3 + var_4 + var_5 + var_6 + var_7 + var_8 + var_9 + var_10 + var_11 + var_12 + var_13 + var_14 + var_15 + var_16 + var_17 + var_18 + var_19 + var_20 + var_21 + var_22 + var_23 + var_24 + var_25 + var_26 + var_27 + var_28 + var_29 + var_30 + var_31 + var_32 + var_33 + var_34 + var_35 + var_36 + var_37 + var_38 + var_39 + var_40 + var_41 + var_42 + var_43 + var_44 + var_45 + var_46 + var_47 + var_48 + var_49 + var_50 + var_51 + var_52 + var_53 + var_54 + var_55 + var_56 + var_57 + var_58 + var_59 + var_60 + var_61 + var_62 + var_63 + var_64 + var_65 + var_66 + var_67 + var_68 + var_69 + var_70 + var_71 + var_72 + var_73 + var_74 + var_75 + var_76 + var_77 + var_78 + var_79 + var_80 + var_81 + var_82 + var_83 + var_84 + var_85 + var_86 + var_87 + var_88 + var_89 + var_90 + var_91 + var_92 + var_93 + var_94 + var_95 + var_96 + var_97 + var_98 + var_99 + var_100 + var_101 + var_102 + var_103 + var_104 + var_105 + var_106 + var_107 + var_108 + var_109 + var_110 + var_111 + var_112 + var_113 + var_114 + var_115 + var_116 + var_117 + var_118 + var_119 + var_120 + var_121 + var_122 + var_123 + var_124 + var_125 + var_126 + var_127 + var_128 + var_129 + var_130 + var_131 + var_132 + var_133 + var_134 + var_135 + var_136 + var_137 + var_138 + var_139 + var_140 + var_141 + var_142 + var_143 + var_144 + var_145 + var_146 + var_147 + var_148 + var_149 + var_150 + var_151 + var_152 + var_153 + var_154 + var_155 + var_156 + var_157 + var_158 + var_159 + var_160 + var_161 + var_162 + var_163 + var_164 + var_165 + var_166 + var_167 + var_168 + var_169 + var_170 + var_171 + var_172 + var_173 + var_174 + var_175 + var_176 + var_177 + var_178 + var_179 + var_180 + var_181 + var_182 + var_183 + var_184 + var_185 + var_186 + var_187 + var_188 + var_189 + var_190 + var_191 + var_192 + var_193 + var_194 + var_195 + var_196 + var_197 + var_198 + var_199', data=merged_df).fit()\n",
        "\n",
        "# Print the ANOVA table\n",
        "print(sm.stats.anova_lm(model, typ=2))\n"
      ],
      "metadata": {
        "id": "A-9LPgWec2a4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}